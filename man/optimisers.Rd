% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimisers.R
\name{optimisers}
\alias{optimisers}
\alias{nelder_mead}
\alias{powell}
\alias{bfgs}
\alias{cg}
\alias{newton_cg}
\alias{l_bfgs_b}
\alias{tnc}
\alias{cobyla}
\alias{slsqp}
\alias{gradient_descent}
\alias{adadelta}
\alias{adagrad}
\alias{adagrad_da}
\alias{adam}
\alias{adamax}
\alias{ftrl}
\alias{proximal_gradient_descent}
\alias{proximal_adagrad}
\alias{nadam}
\alias{rms_prop}
\title{optimisation methods}
\usage{
nelder_mead()

powell()

bfgs()

cg()

newton_cg()

l_bfgs_b()

tnc()

cobyla()

slsqp()

gradient_descent(learning_rate = 0.01, momentum = 0, nesterov = FALSE)

adadelta(learning_rate = 0.001, rho = 1, epsilon = 1e-08)

adagrad(learning_rate = 0.8, initial_accumulator_value = 0.1, epsilon = 1e-08)

adagrad_da(
  learning_rate = 0.8,
  global_step = 1L,
  initial_gradient_squared_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

adam(
  learning_rate = 0.1,
  beta1 = 0.9,
  beta2 = 0.999,
  amsgrad = FALSE,
  epsilon = 1e-08
)

adamax(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)

ftrl(
  learning_rate = 1,
  learning_rate_power = -0.5,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0,
  l2_shrinkage_regularization_strength = 0,
  beta = 0
)

proximal_gradient_descent(
  learning_rate = 0.01,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

proximal_adagrad(
  learning_rate = 1,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

nadam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)

rms_prop(
  learning_rate = 0.1,
  rho = 0.9,
  momentum = 0,
  epsilon = 1e-10,
  centered = FALSE
)
}
\arguments{
\item{learning_rate}{the size of steps (in parameter space) towards the
optimal value. Default value 0.01}

\item{momentum}{hyperparameter that accelerates gradient descent in the
relevant direction and dampens oscillations. Defaults to 0, which is
vanilla gradient descent.}

\item{nesterov}{Whether to apply Nesterov momentum. Defaults to FALSE.}

\item{rho}{the decay rate}

\item{epsilon}{a small constant used to condition gradient updates}

\item{initial_accumulator_value}{initial value of the 'accumulator' used to
tune the algorithm}

\item{global_step}{the current training step number}

\item{initial_gradient_squared_accumulator_value}{initial value of the
accumulators used to tune the algorithm}

\item{l1_regularization_strength}{L1 regularisation coefficient (must be 0 or
greater)}

\item{l2_regularization_strength}{L2 regularisation coefficient (must be 0 or
greater)}

\item{beta1}{exponential decay rate for the 1st moment estimates}

\item{beta2}{exponential decay rate for the 2nd moment estimates}

\item{amsgrad}{Boolean. Whether to apply AMSGrad variant of this algorithm
from the paper "On the Convergence of Adam and beyond". Defaults to FALSE.}

\item{learning_rate_power}{power on the learning rate, must be 0 or less}

\item{l2_shrinkage_regularization_strength}{A float value, must be greater
than or equal to zero. This differs from L2 above in that the L2 above is
a stabilization penalty, whereas this L2 shrinkage is a magnitude penalty.
When input is sparse shrinkage will only happen on the active weights.}

\item{beta}{A float value, representing the beta value from the paper by
\href{https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf}{McMahan et al 2013}. Defaults to 0}

\item{centered}{Boolean. If TRUE, gradients are normalized by the estimated
variance of the gradient; if FALSE, by the uncentered second moment.
Setting this to TRUE may help with training, but is slightly more
expensive in terms of computation and memory. Defaults to FALSE.}
}
\value{
an \code{optimiser} object that can be passed to \code{\link[=opt]{opt()}}.
}
\description{
Functions to set up optimisers (which find parameters that
maximise the joint density of a model) and change their tuning parameters,
for use in \code{\link[=opt]{opt()}}. For details of the algorithms and how to
tune them, see the
\href{https://docs.scipy.org/doc/scipy-1.8.0/html-scipyorg/reference/optimize.html#optimization}{SciPy optimiser docs} or the
\href{https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib}{TensorFlow optimiser docs}.
}
\details{
The optimisers \code{powell()}, \code{cg()}, \code{newton_cg()},
\code{l_bfgs_b()}, \code{tnc()}, \code{cobyla()}, and \code{slsqp()} are
deprecated. They will be removed in greta 0.4.0, since they will no longer
be available in TensorFlow 2.0, on which that version of greta will depend.
}
\note{
This optimizer isn't supported in TF2, so proceed with caution. See
the \href{https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdagradDAOptimizer}{TF docs on AdagradDAOptimiser} for more detail.

This optimizer isn't supported in TF2, so proceed with caution. See
the \href{https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/ProximalGradientDescentOptimizer}{TF docs on AdagradDAOptimiser} for more detail.

This optimizer isn't supported in TF2, so proceed with caution. See
the \href{https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/ProximalAdagradOptimizer}{TF docs on AdagradDAOptimiser} for more detail.
}
\examples{
\dontrun{
# use optimisation to find the mean and sd of some data
x <- rnorm(100, -2, 1.2)
mu <- variable()
sd <- variable(lower = 0)
distribution(x) <- normal(mu, sd)
m <- model(mu, sd)

# configure optimisers & parameters via 'optimiser' argument to opt
opt_res <- opt(m, optimiser = bfgs())

# compare results with the analytic solution
opt_res$par
c(mean(x), sd(x))
}
}
