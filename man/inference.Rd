% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/inference.R
\name{inference}
\alias{inference}
\alias{mcmc}
\alias{stashed_samples}
\alias{extra_samples}
\alias{opt}
\title{statistical inference on greta models}
\usage{
mcmc(model, sampler = hmc(), n_samples = 1000, thin = 1,
  warmup = 1000, chains = 1, n_cores = NULL, verbose = TRUE,
  pb_update = 50, initial_values = NULL)

stashed_samples()

extra_samples(draws, n_samples = 1000, thin = 1, n_cores = NULL,
  verbose = TRUE, pb_update = 50)

opt(model, optimiser = bfgs(), max_iterations = 100,
  tolerance = 1e-06, initial_values = NULL)
}
\arguments{
\item{model}{greta_model object}

\item{sampler}{sampler used to draw values in MCMC. See \code{\link{samplers}} for options.}

\item{n_samples}{number of MCMC samples to draw per chain (after any warm-up, but
before thinning)}

\item{thin}{MCMC thinning rate; every \code{thin} samples is retained,
the rest are discarded}

\item{warmup}{number of samples to spend warming up the mcmc sampler.
During this phase the sampler moves toward the highest density area and
tunes sampler hyperparameters.}

\item{chains}{number of MCMC chains to run}

\item{n_cores}{the maximum number of CPU cores used by \emph{each} chain.}

\item{verbose}{whether to print progress information to the console}

\item{pb_update}{how regularly to update the progress bar (in iterations)}

\item{initial_values}{an optional vector (or list of vectors, for multiple
chains) of initial values for the free parameters in the model. These will
be used as the starting point for sampling/optimisation.}

\item{draws}{an mcmc.list object returned by \code{mcmc} or
\code{stashed_samples}}

\item{optimiser}{an \code{optimiser} object giving the optimisation algorithm
and parameters See \code{\link{optimisers}}.}

\item{max_iterations}{the maximum number of iterations before giving up}

\item{tolerance}{the numerical tolerance for the solution, the optimiser
stops when the (absolute) difference in the joint density between
successive iterations drops below this level}
}
\value{
\code{mcmc}, \code{stashed_samples} & \code{extra_samples} - an
  \code{mcmc.list} object that can be analysed using functions from the coda
  package. This will contain mcmc samples of the greta arrays used to create
  \code{model}.

\code{opt} - a list containing the following named elements:
  \itemize{
   \item{par} {the best set of parameters found}
   \item{value} {the log joint density of the model at the parameters par}
   \item{iterations} {the number of iterations taken by the optimiser}
   \item{convergence} {an integer code, 0 indicates successful completion,
    1 indicates the iteration limit \code{max_iterations} had been reached} }
}
\description{
Carry out statistical inference on greta models by
  MCMC or likelihood/posterior optimisation.
}
\details{
For \code{mcmc()} if \code{verbose = TRUE}, the progress bar shows
  the number of iterations so far and the expected time to complete the phase
  of model fitting (warmup or sampling). Updating the progress bar regularly
  slows down sampling, by as much as 9 seconds per 1000 updates. So if you
  want the sampler to run faster, you can change \code{pb_update} to increase
  the number of iterations between updates of the progress bar, or turn the
  progress bar off altogether by setting \code{verbose = FALSE}.

  Occasionally, a proposed set of parameters can cause numerical instability
  (I.e. the log density or its gradient is \code{NA}, \code{Inf} or
  \code{-Inf}); normally because the log joint density is so low that it
  can't be represented as a floating point number. When this happens, the
  progress bar will also display the proportion of samples so far that were
  'bad' (numerically unstable) and therefore rejected.
  If you're getting a lot of numerical instability, you might want to
  manually define starting values to move the sampler into a more reasonable
  part of the parameter space.

  Multiple mcmc chains can be run in parallel by setting the execution plan
  with the \code{future} package. Only \code{plan(multisession)} futures or
  \code{plan(cluster)} futures that don't use fork clusters are allowed,
  since forked processes conflict with tensorflow's parallelism.

  If \code{n_cores = NULL} and mcmc chains are being run sequentially, each
  chain will be allowed to use all CPU cores. If chains are being run in
  parallel, \code{n_cores} will be set so that \code{n_cores * chains} is
  less than the number of CPU cores.

If the sampler is aborted before finishing, the samples collected so
  far can be retrieved with \code{stashed_samples()}. Only samples from the
  sampling phase will be returned.

Samples returned by \code{mcmc()} and \code{stashed_samples()} can
  be added to with \code{extra_samples()}. This continues the chain from the
  last value of the previous chain and uses the same sampler and model as was
  used to generate the previous samples. It is not possible to change the
  sampler or extend the warmup period.
}
\examples{
\dontrun{
# define a simple model
mu <- variable()
sigma <- lognormal(1, 0.1)
x <- rnorm(10)
distribution(x) <- normal(mu, sigma)
m <- model(mu, sigma)

# carry out mcmc on the model
draws <- mcmc(m,
              n_samples = 100,
              warmup = 10)
}
\dontrun{
# find the MAP estimate
opt_res <- opt(m)
}
}
